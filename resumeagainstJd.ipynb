{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOiggQ+gWN+8pVjba8TRVta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Domminique/CHF/blob/master/resumeagainstJd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LotuMDfb4Y3u",
        "outputId": "8b1fae3f-e6a7-4b42-b175-ac0fea72eb37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#Resume Phrase Matcher code\n",
        "!pip install PyPDF2\n",
        "\n",
        "#importing all required libraries\n",
        "\n",
        "import PyPDF2\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "#Function to read resumes from the folder one by one\n",
        "mypath='D:/NLP_Resume/Candidate Resume' #enter your path here where you saved the resumes\n",
        "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
        "\n",
        "def pdfextract(file):\n",
        "    fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
        "    countpage = fileReader.getNumPages()\n",
        "    count = 0\n",
        "    text = []\n",
        "    while count < countpage:    \n",
        "        pageObj = fileReader.getPage(count)\n",
        "        count +=1\n",
        "        t = pageObj.extractText()\n",
        "        print (t)\n",
        "        text.append(t)\n",
        "    return text\n",
        "\n",
        "#function to read resume ends\n",
        "\n",
        "\n",
        "#function that does phrase matching and builds a candidate profile\n",
        "def create_profile(file):\n",
        "    text = pdfextract(file) \n",
        "    text = str(text)\n",
        "    text = text.replace(\"\\\\n\", \"\")\n",
        "    text = text.lower()\n",
        "    #below is the csv where we have all the keywords, you can customize your own\n",
        "    keyword_dict = pd.read_csv('D:/NLP_Resume/resume/template_new.csv')\n",
        "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
        "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
        "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
        "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
        "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
        "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
        "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
        "\n",
        "    matcher = PhraseMatcher(nlp.vocab)\n",
        "    matcher.add('Stats', None, *stats_words)\n",
        "    matcher.add('NLP', None, *NLP_words)\n",
        "    matcher.add('ML', None, *ML_words)\n",
        "    matcher.add('DL', None, *DL_words)\n",
        "    matcher.add('R', None, *R_words)\n",
        "    matcher.add('Python', None, *python_words)\n",
        "    matcher.add('DE', None, *Data_Engineering_words)\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    d = []  \n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
        "        span = doc[start : end]  # get the matched slice of the doc\n",
        "        d.append((rule_id, span.text))      \n",
        "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
        "    \n",
        "    ## convertimg string of keywords to dataframe\n",
        "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
        "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
        "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
        "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
        "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
        "    \n",
        "    base = os.path.basename(file)\n",
        "    filename = os.path.splitext(base)[0]\n",
        "       \n",
        "    name = filename.split('_')\n",
        "    name2 = name[0]\n",
        "    name2 = name2.lower()\n",
        "    ## converting str to dataframe\n",
        "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
        "    \n",
        "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
        "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
        "\n",
        "    return(dataf)\n",
        "        \n",
        "#function ends\n",
        "        \n",
        "#code to execute/call the above functions\n",
        "\n",
        "final_database=pd.DataFrame()\n",
        "i = 0 \n",
        "while i < len(onlyfiles):\n",
        "    file = onlyfiles[i]\n",
        "    dat = create_profile(file)\n",
        "    final_database = final_database.append(dat)\n",
        "    i +=1\n",
        "    print(final_database)\n",
        "\n",
        "    \n",
        "#code to count words under each category and visulaize it through Matplotlib\n",
        "\n",
        "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
        "final_database2.reset_index(inplace = True)\n",
        "final_database2.fillna(0,inplace=True)\n",
        "new_data = final_database2.iloc[:,1:]\n",
        "new_data.index = final_database2['Candidate Name']\n",
        "#execute the below line if you want to see the candidate profile in a csv format\n",
        "#sample2=new_data.to_csv('sample.csv')\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(25,7), stacked=True)\n",
        "labels = []\n",
        "for j in new_data.columns:\n",
        "    for i in new_data.index:\n",
        "        label = str(j)+\": \" + str(new_data.loc[i][j])\n",
        "        labels.append(label)\n",
        "patches = ax.patches\n",
        "for label, rect in zip(labels, patches):\n",
        "    width = rect.get_width()\n",
        "    if width > 0:\n",
        "        x = rect.get_x()\n",
        "        y = rect.get_y()\n",
        "        height = rect.get_height()\n",
        "        ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.6/dist-packages (1.26.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9fc8a59dd989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#Function to read resumes from the folder one by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmypath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'D:/NLP_Resume/Candidate Resume'\u001b[0m \u001b[0;31m#enter your path here where you saved the resumes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0monlyfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpdfextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/NLP_Resume/Candidate Resume'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bk0Dy6b4s6d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}